{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fashion-MNIST MLP Classifier\n",
        "\n",
        "This notebook trains a simple fully-connected neural network (MLP) on the Fashion-MNIST dataset to achieve >85% test accuracy. It includes data loading, model definition, training, evaluation (accuracy and confusion matrix), example predictions, and training curves.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports and setup\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score\n",
        "\n",
        "# Reproducibility\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data loading: Fashion-MNIST\n",
        "batch_size = 64\n",
        "\n",
        "# Transform: scale to [0,1]\n",
        "transform = transforms.ToTensor()\n",
        "\n",
        "train_dataset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "class_names = train_dataset.classes\n",
        "print('Classes:', class_names)\n",
        "print('Train size:', len(train_dataset), 'Test size:', len(test_dataset))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# MLP model per spec\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Flatten(),                # 28x28 -> 784\n",
        "            nn.Linear(28*28, 256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(128, 10),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "model = MLP().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "print(model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training and evaluation utilities\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in loader:\n",
        "        images = images.to(device, non_blocking=True)\n",
        "        labels = labels.to(device, non_blocking=True)\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        preds = outputs.argmax(dim=1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    avg_loss = running_loss / total\n",
        "    acc = correct / total\n",
        "    return avg_loss, acc\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    for images, labels in loader:\n",
        "        images = images.to(device, non_blocking=True)\n",
        "        labels = labels.to(device, non_blocking=True)\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        preds = outputs.argmax(dim=1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "        all_preds.append(preds.cpu().numpy())\n",
        "        all_labels.append(labels.cpu().numpy())\n",
        "\n",
        "    avg_loss = running_loss / total\n",
        "    acc = correct / total\n",
        "    all_preds = np.concatenate(all_preds)\n",
        "    all_labels = np.concatenate(all_labels)\n",
        "    return avg_loss, acc, all_preds, all_labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train loop\n",
        "num_epochs = 8  # between 5 and 10\n",
        "train_losses, train_accs = [], []\n",
        "test_losses, test_accs = [], []\n",
        "\n",
        "start = time.time()\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    tr_loss, tr_acc = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
        "    te_loss, te_acc, _, _ = evaluate(model, test_loader, criterion, device)\n",
        "\n",
        "    train_losses.append(tr_loss); train_accs.append(tr_acc)\n",
        "    test_losses.append(te_loss); test_accs.append(te_acc)\n",
        "\n",
        "    print(f\"Epoch {epoch:02d}/{num_epochs} | Train loss {tr_loss:.4f} acc {tr_acc*100:.2f}% | Test loss {te_loss:.4f} acc {te_acc*100:.2f}%\")\n",
        "\n",
        "elapsed = time.time() - start\n",
        "print(f\"Training completed in {elapsed:.1f}s\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot training curves\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "axes[0].plot(train_losses, label='Train')\n",
        "axes[0].plot(test_losses, label='Test')\n",
        "axes[0].set_title('Loss per epoch')\n",
        "axes[0].set_xlabel('Epoch')\n",
        "axes[0].set_ylabel('Loss')\n",
        "axes[0].legend()\n",
        "\n",
        "axes[1].plot([a*100 for a in train_accs], label='Train')\n",
        "axes[1].plot([a*100 for a in test_accs], label='Test')\n",
        "axes[1].set_title('Accuracy per epoch')\n",
        "axes[1].set_xlabel('Epoch')\n",
        "axes[1].set_ylabel('Accuracy (%)')\n",
        "axes[1].legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Final evaluation and confusion matrix\n",
        "# Compute final metrics on train and test\n",
        "tr_loss, tr_acc, tr_preds, tr_labels = evaluate(model, train_loader, criterion, device)\n",
        "te_loss, te_acc, te_preds, te_labels = evaluate(model, test_loader, criterion, device)\n",
        "print(f\"Final Train Acc: {tr_acc*100:.2f}% | Test Acc: {te_acc*100:.2f}%\")\n",
        "\n",
        "# Confusion matrix on test\n",
        "cm = confusion_matrix(te_labels, te_preds, labels=list(range(10)))\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
        "fig, ax = plt.subplots(figsize=(6,6))\n",
        "disp.plot(ax=ax, xticks_rotation=45, cmap='Blues', colorbar=False)\n",
        "ax.set_title('Fashion-MNIST Confusion Matrix (Test)')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example predictions: correct and incorrect\n",
        "@torch.no_grad()\n",
        "def show_examples(model, loader, class_names, max_correct=5, max_incorrect=5):\n",
        "    model.eval()\n",
        "    correct_imgs, correct_preds, correct_labels = [], [], []\n",
        "    incorrect_imgs, incorrect_preds, incorrect_labels = [], [], []\n",
        "    for images, labels in loader:\n",
        "        outputs = model(images.to(device))\n",
        "        preds = outputs.argmax(dim=1).cpu()\n",
        "        for img, pred, lbl in zip(images, preds, labels):\n",
        "            if pred == lbl and len(correct_imgs) < max_correct:\n",
        "                correct_imgs.append(img.squeeze(0))\n",
        "                correct_preds.append(pred.item())\n",
        "                correct_labels.append(lbl.item())\n",
        "            elif pred != lbl and len(incorrect_imgs) < max_incorrect:\n",
        "                incorrect_imgs.append(img.squeeze(0))\n",
        "                incorrect_preds.append(pred.item())\n",
        "                incorrect_labels.append(lbl.item())\n",
        "            if len(correct_imgs) == max_correct and len(incorrect_imgs) == max_incorrect:\n",
        "                break\n",
        "        if len(correct_imgs) == max_correct and len(incorrect_imgs) == max_incorrect:\n",
        "            break\n",
        "\n",
        "    # Plot\n",
        "    n_rows = 2\n",
        "    n_cols = max(max_correct, max_incorrect)\n",
        "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(2.5*n_cols, 5))\n",
        "    for i in range(n_cols):\n",
        "        if i < len(correct_imgs):\n",
        "            axes[0, i].imshow(correct_imgs[i], cmap='gray')\n",
        "            axes[0, i].set_title(f\"Correct: {class_names[correct_preds[i]]}\")\n",
        "            axes[0, i].axis('off')\n",
        "        else:\n",
        "            axes[0, i].axis('off')\n",
        "        if i < len(incorrect_imgs):\n",
        "            axes[1, i].imshow(incorrect_imgs[i], cmap='gray')\n",
        "            axes[1, i].set_title(f\"Pred: {class_names[incorrect_preds[i]]}\\nTrue: {class_names[incorrect_labels[i]]}\")\n",
        "            axes[1, i].axis('off')\n",
        "        else:\n",
        "            axes[1, i].axis('off')\n",
        "    axes[0,0].set_ylabel('Correct', fontsize=12)\n",
        "    axes[1,0].set_ylabel('Incorrect', fontsize=12)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "show_examples(model, test_loader, class_names)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Conclusion\n",
        "\n",
        "This simple MLP with two ReLU hidden layers achieved >85% test accuracy on Fashion-MNIST. While effective, a convolutional neural network (CNN) typically performs better on image data. Further improvements could include adding dropout, weight decay, longer training, or switching to a small CNN.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### How to run\n",
        "\n",
        "- Install dependencies: see `requirements.txt`.\n",
        "- Run the notebook `fashion_mnist_mlp.ipynb` end-to-end.\n",
        "- GPU is optional; CPU also works.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
